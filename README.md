# Quantization LLMs
 This repository contains a custom W8A16 Quantizer, that performs quantization by replacing the troch.nn.Linear layers in LLMs.
